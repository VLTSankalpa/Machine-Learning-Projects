# -*- coding: utf-8 -*-
"""EE7206 MACHINE LEARNING Project Report.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_b_rQnxflmFZEMl5gdo53tkS8ZjX43W9

**NAME : SANKALPA V.L.T.**

**REG No. : EG/2015/2757**

**E-mail : wltsankalpa@gmail.com**

**Contact No : 077-4588562**

---

# Q1 
## part 1 :- Identifing outlier trades based on Executed Price & Executed Qty using Hierarchical Clustering
An outlier is a data point that differs significantly from other observations. Clustering is the task of dividing the population or data points into a number of groups such that data points in the same groups are more similar and data points in different groups are more differs. Therefore, when clusters form outlier data points will be cluster in to an outlier clusters.
"""

# Importing the libraries

import matplotlib.pyplot as plt
import pandas as pd
import scipy.cluster.hierarchy as sch
from apyori import apriori
from sklearn.cluster import AgglomerativeClustering
# Upload Trade.csv file to google colab
from google.colab import files
uploaded = files.upload()

"""### Data preprocessing"""

# Importing the trades data as pandas DataFrame
dataset = pd.read_csv('Trades.csv')
dataset

# Filtering the trades of stock ES0158252033 and create a new DataFrame
Trades = dataset.loc[dataset.Stock=='ES0158252033', :]
Trades

# Add indexing column to Dataframe (Lets consider this index represent the Trade Date)
Trades['Index'] = range(1, len(Trades) + 1)
Trades

# Create NumPy array with Execute Qty and Execute Price of Trades
X = Trades.iloc[:, [ 1, 2]].values
X

"""### Using the elbow method to find the optimal number of clusters suitable to identify outliners
The elbow method plot graph between the number of clusters and **Within-Cluster-Sum-of-Squares (WCSS)**. When the gradient of graph become constant corresponding number of clusters can be consider as the optimal number of clusters.
"""

# change the font siXe on a matplotlib plot
font = {'family' : 'normal','weight' : 'bold','size'   : 15}
plt.rc('font', **font)

# change the graph siXe of a matplotlib plot
plt.rcParams['figure.figsize'] = (20, 20)

from sklearn.cluster import KMeans
wcss = []
for i in range(1, 9):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)
plt.plot(range(1, 9), wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

"""According to above graph we can identify optimal number of clusters as five for this problem.
### Using the dendrogram to find the optimal number of clusters suitable to identify outliners
Since the main point of Hierarchical Clustering is to make the dendrogram, because dendrogram contain the memory of Hierarchical Clustering algorithm, then work your way down to see the diﬀerent combinations of clusters until having a single large cluter. Therefore in Hierarchical Clustering to double check the optimal number of clusters its possible to use **dendrogram**.The dendrogram itself that allows to ﬁnd the best clustering conﬁguration.
"""

# plot dendrogram for X array
dendrogram_X = sch.dendrogram(sch.linkage(X, method = 'ward'))
plt.title('Dendrogram of array X')
plt.xlabel('Trades')
plt.ylabel('Euclidean distances')
plt.show()

"""by drawing line across 500 euclidean distance it possible to determine the optimal number of clusters as five clusters

### Apply Hierarchical Clustering



```

```
"""

# Fitting Hierarchical Clustering to the array X
hc = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')
# Create Array with clusters
X_hc = hc.fit_predict(X)
X_hc

# Add a X_hc array as Cluster column to a Trades dataframe
Trades['Cluster'] = X_hc
Trades

"""### Visualising the clusters"""

# change the graph size of a matplotlib plot
plt.rcParams['figure.figsize'] = (30, 15)
# Visualising the clusters
plt.scatter(X[X_hc == 0, 0], X[X_hc == 0, 1], s = 10, c = 'black', label = 'Cluster 0')
plt.scatter(X[X_hc == 1, 0], X[X_hc == 1, 1], s = 10, c = 'blue', label = 'Cluster 1')
plt.scatter(X[X_hc == 2, 0], X[X_hc == 2, 1], s = 10, c = 'green', label = 'Cluster 2')
plt.scatter(X[X_hc == 3, 0], X[X_hc == 3, 1], s = 10, c = 'red', label = 'Cluster 3')
plt.scatter(X[X_hc == 4, 0], X[X_hc == 4, 1], s = 10, c = 'orange', label = 'Cluster 4')
plt.title('Clusters of trades')
plt.xlabel('Executed Qty')
plt.ylabel('Executed Price')
plt.legend()
plt.show()

"""By observing cluster visualization scatter plot, it’s possible to notice that cluster 3 (brown colour in scatter plot) has lowest data-point count comparing with other clusters.
### Calculating statistical information of clusters
Use group by pandas aggregate to calculate statistical information of clusters based on Executed Qty, Executed price and index (this index represent the Trade date)
"""

# Calculate statistical information of clusters based on Executed Qty of trades
Cluster_Statistics_Qty = Trades.groupby("Cluster")['Executed Qty'].describe()
Cluster_Statistics_Qty

"""When observing above cluster statistical information of executed Qty of trades. All five clusters contain trades that has different statistical parameters. Especially cluster its possible to observe,

1.   Trades which has executed Qty between **1 to 28** clustered to cluster **4**

2.   Trades which has executed Qty between **27 to 64** clustered to cluster **1**

3.   Trades which has executed Qty between **64 to 112** clustered to cluster **2**

4.   Trades which has executed Qty between **113 to 182** clustered to cluster **0**

5.   Trades which has executed Qty between **183 to 201** clustered to cluster **3**

Therefore, it possible to come to conclusion that, executed Qty do contribute to form an outlier trades.
"""

# Calculate statistical information of clusters based on Executed Price of trades
Cluster_Statistics_Price = Trades.groupby("Cluster")['Executed Price'].describe()
Cluster_Statistics_Price

"""When observing above cluster statistical information of executed price of trades. All five clusters contain trades that has approximately same statistical parameters,

1.   mean ≈ 12.3
2.   standard deviation ≈ 2.8
3.   min ≈ 8.45
4.   25% ≈ 10.8
5.   50% ≈ 11.5
6.   75 ≈13.5
7.   max ≈ 20

Therefore, it possible to come to conclusion that, executed price doesn’t contribute to form an outlier trade since frequent rapid price changes not possible to observed in give dataset.
"""

# Calculate statistical information of clusters based on Index of trades
Cluster_Statistics_index = Trades.groupby("Cluster")['Index'].describe()
Cluster_Statistics_index

"""When observing above cluster statistical information of trade indexes. All five clusters contain trades spead all over full index range form 0 to 1980. Especially by looking at minimum and maximum index of each cluster, it is possible to conclude that each cluster has data points in all over full index range. Therefore, according to above cluster statistic of executed Qty if we sort all five clusters according to count of data points within the cluster as follow, 

***Cluster 3 – 154 data points (7.78%)***

**Cluster 0 – 349 data points (17.63%)**

**Cluster 4 – 375 data points (18.94%)**

**Cluster 1 – 474 data points (23.94%)**

**Cluster 2 – 628 data points (31.72%)**

Therefore, the cluster that has lowest count of data points (**7.78 % of all data points**) makes **outlier cluster, which is cluster 3**. Finally its feasible to concluded all the trade that enrol executed qty between 184 and 201 are outlier trades. 

### Outlier Trades
"""

# Create outlier Trdaes Dataframe

Cluster = [3]
Outlier_Trades = Trades[Trades.Cluster.isin(Cluster)]
Outlier_Trades

"""## part 2 :- Identifing outlier traders based on sum of Executed Qty using Hierarchical Clustering

Form above part 1 it’s possible to conclude that outlier trades form due to executed quantity of trades (the trade that enrol executed qty between 184 and 201) Therefore its possible to identify the outlier traders using hierarchical clustering based on the sum of executed qty for each buyer.
### Data preprocessing with pandas
"""

# Create a new DataFrame contain sum of Executed Qty for each traders who brought stock ES0158252033 
Traders = dataset[dataset.Stock=="ES0158252033"].groupby("Buy Broker ID")['Executed Qty'].sum().reset_index()
Traders

# Add indexing column to Traders Dataframe
Traders['Index'] = range(1, len(Traders) + 1)
Traders

# Create NumPy array with sum of Executed Qty of Traders
Y = Traders.iloc[:, [2, 1]].values
Y

"""### Using the dendrogram to find the optimal number of clusters suitable to identify outliners"""

# change the graph siXe of a matplotlib plot
plt.rcParams['figure.figsize'] = (20, 20)

from sklearn.cluster import KMeans
wcss = []
for i in range(1, 9):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
    kmeans.fit(Y)
    wcss.append(kmeans.inertia_)
plt.plot(range(1, 9), wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

"""### Apply Hierarchical Clustering"""

# Fitting Hierarchical Clustering to the array X
hc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')
# Create Array with clusters
Y_hc = hc.fit_predict(Y)
Y_hc

# Add a X_hc array as Cluster column to a Trades dataframe
Traders['Cluster'] = Y_hc
Traders

"""### Visualising the clusters"""

# change the graph size of a matplotlib plot
plt.rcParams['figure.figsize'] = (20, 10)
# Visualising the clusters
plt.scatter(Y[Y_hc == 0, 0], Y[Y_hc == 0, 1], s = 30, c = 'red', label = 'Cluster 0')
plt.scatter(Y[Y_hc == 1, 0], Y[Y_hc == 1, 1], s = 30, c = 'orange', label = 'Cluster 1')
plt.scatter(Y[Y_hc == 2, 0], Y[Y_hc == 2, 1], s = 30, c = 'green', label = 'Cluster 2')
plt.title('Clusters of traders')
plt.xlabel('Trader Index')
plt.ylabel('Sum of Executed Qty')
plt.legend()
plt.show()

"""### Calculating statistical information of clusters"""

# Calculating statistical information of clusters
Cluster_Statistics = Traders.groupby("Cluster")['Executed Qty'].describe()
Cluster_Statistics

"""### Outlier Traders"""

# Create outlier Trdaes Dataframe
Cluster = [0, 1]
Outlier_Traders= Traders[Traders.Cluster.isin(Cluster)]
Outlier_Traders

"""# Q2
## Identifing collusive trader group using Apriori Algorithm

**Association rule learning** is a rule-based machine learning method for discovering complex relationships between variables in large dataset. **Apriori** is an algorithm that use for frequent item set mining and association rule learning within databsets. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database.

**Stock market manipulations** as an organized **collusive trader groups** in stock market can be consider as one of major formats of market abuse, a Stock market manipulations can be extremely damaging to the proper functioning and integrity of capital markets. 

Market manipulation refers to artificially inflating or deflating the price of a stocks or otherwise influencing the behavior of the market for personal gain. Two common types of stock manipulation are pump and dump and poop and scoop. The pump and dump is the most frequently used manipulation to inflate a microcap stock by artificially buying and then sell out, leaving later followers to hold the loss.
Manipulation is variously called price manipulation, stock manipulation, and market manipulation. However, in this approach let’s focus more about **price manipulation** and **run Apriori to identify frequent traders within the segments which shows considerable amount of stock price changes**.

## Data preprocessing with pandas
"""

# Create NumPy array with Execute Price of Trades
Z = Trades.iloc[:, [ 8, 2]].values
Z

"""### Visualising the variation of executed price within the dataset"""

# change the graph size of a matplotlib plot
plt.rcParams['figure.figsize'] = (30, 10)
# Plotting the graph of Executed Price of Stock ES0158252033
plt.plot(Z[:,0], Z[:,1])
plt.title('Executed Price of Stock ES0158252033')
plt.xlabel('Trade Index')
plt.ylabel('Executed Price')
plt.show()

"""By observing above price variation within the dataset its clear the requirement of some technique to identify the segment within dataset that has considerable amount of price variations. Hierarchical clustering with larger of clusters **(200 clusters)** can used to sample dataset into smaller segments. Then the standard deviation of the data points within each cluster can used as parameter of price variance present in the cluster. Then Apriori algorithm can run to identify the frequent traders who trade in these segments.

### Applying Hierarchical Clustering to identify segment where considerable amount of price variations are present within the dataset.
"""

# Fitting Hierarchical Clustering to the array Z
hc = AgglomerativeClustering(n_clusters = 200, affinity = 'euclidean', linkage = 'ward')
# Create Array with clusters
Z_hc = hc.fit_predict(Z)
Z_hc

# Add a Z_hc array as Cluster column to a Trades dataframe
Trades['Cluster'] = Z_hc
Trades

"""### Identify the clusters which has considerable amount of price variations"""

# compute a summary statistic for each clusters using groupby aggregation
Cluster_Statistics_Price = Trades.groupby("Cluster")['Executed Price'].describe()
# Add a index clounm to Cluster Statistics Price dataframe
Cluster_Statistics_Price['Index'] = range(0, len(Cluster_Statistics_Price)+0)
# Sort all clusters according to ascending order by standard deviation
Cluster_Statistics_Price = Cluster_Statistics_Price.sort_values(by ='std', ascending=False).reset_index()
Cluster_Statistics_Price

"""Lets select all the clusters which has standard deviation more than 0.1 to input in to Apriori algorithm. From above summary statistic for each clusters using groupby aggregation we can identify 52 clusters which has standard deivation more than 0.1."""

# Drop all clusters has standard deviation less than 0.1
T_Clusters = Cluster_Statistics_Price.iloc[0:52, [9]]
T_Clusters

"""### Create a list of lists to input to Apriori algorithm

Apriori library I am going to use requires input dataset to be in the form of a list of lists. Therefore as a final step of the Data preprocessing process lets create transaction list of list.
"""

# Create a list of lists ()
transactions = (
     [Trades.loc[Trades.Cluster==0, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==0, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==2, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==2, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==93, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==93, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==38, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==38, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==5, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==5, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==66, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==66, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==8, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==8, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==31, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==31, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==65, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==65, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==27, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==27, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==3, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==3, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==108, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==108, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==194, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==194, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==172, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==172, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==52, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==52, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==109, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==109, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==28, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==28, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==35, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==35, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==39, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==39, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==47, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==47, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==123, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==123, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==158, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==158, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==173, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==173, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==81, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==81, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==147, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==147, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==77, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==77, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==49, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==49, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==167, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==167, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==95, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==95, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==16, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==16, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==134, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==134, :]['Sell Broker ID'].unique().tolist()] + 
     [Trades.loc[Trades.Cluster==6, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==6, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==13, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==13, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==60, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==60, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==146, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==146, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==64, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==64, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==191, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==191, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==132, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==132, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==155, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==155, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==83, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==83, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==50, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==50, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==128, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==128, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==40, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==40, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==186, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==186, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==137, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==137, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==17, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==17, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==29, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==29, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==97, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==97, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==91, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==91, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==68, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==68, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==85, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==85, :]['Sell Broker ID'].unique().tolist()] +
     [Trades.loc[Trades.Cluster==10, :]['Buy Broker ID'].unique().tolist() + Trades.loc[Trades.Cluster==10, :]['Sell Broker ID'].unique().tolist()])
transactions

"""## Training Apriori on the dataset to identify potential collusive trader groups (Model forming)"""

rules_test = apriori(transactions, min_support = 0.1,min_confidence = 0.3, min_lift = 1.0001)
# Create a list with all potential collusive trader groups
results_test = list(rules_test)
# Visualising the number of potential collusive trader groups  
print(len(results_test))

"""## Visualising the potential collusive trader groups"""

the_rules = [] 
for result in results_test: 
    the_rules.append({'Collusive Trader Groups Test': ','.join(result.items),
                      'Support':result.support, 
                      'Confidence':result.ordered_statistics[0].confidence,
                      'Lift':result.ordered_statistics[0].lift})
# Create a dataframe with all potential collusive trader groups
collusive_trader_groups_test = (pd.DataFrame(the_rules, columns = ['Collusive Trader Groups Test', 'Support', 'Confidence', 'Lift'])).sort_values(by ='Support', ascending=False)
# Sort all potential collusive trader groups according to ascending order by support
collusive_trader_groups_test = collusive_trader_groups_test.sort_values(by ='Support', ascending=False)
collusive_trader_groups_test

"""### Training Apriori on the transaction list to filter best collusive trader groups ( Model Tuning)

As a step of model tuning in order to filter out strongest rules form above 717 potential rules, lets set the parameters of Apriori algorithm as follow,

**Minimum Support = 0.15**

**Minimum Confidence = 0.75**

**Minimum Lift = 2**

**Minimum length = 2**
"""

rules = apriori(transactions, min_support = 0.15, min_confidence = 0.75, min_lift = 2, min_length = 2)
# Create a list with all collusive trader groups
results = list(rules)
# Visualising the number of collusive trader groups
print(len(results))

"""## Visualising the final collusive trader groups"""

the_rules = [] 
for result in results: 
    the_rules.append({'Collusive Trader Groups': ','.join(result.items),
                      'Support':result.support, 
                      'Confidence':result.ordered_statistics[0].confidence,
                      'Lift':result.ordered_statistics[0].lift})
# Create a dataframe with all collusive trader groups 
collusive_trader_groups = pd.DataFrame(the_rules, columns = ['Collusive Trader Groups', 'Support', 'Confidence', 'Lift'])
collusive_trader_groups

"""As a conclusion, we can identify **C11084986** and **A2007006** traders appear together within 10 clusters out of selected 52 clusters. In addition, **C11084986**, **A11288376** and **A2007006** traders appear together within 8 clusters out of selected 52 clusters."""