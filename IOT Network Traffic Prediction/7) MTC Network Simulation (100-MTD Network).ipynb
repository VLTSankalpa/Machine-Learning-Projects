{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTC Network Simulation (100-MTD Network)\n",
    "\n",
    "Extended MTC network simulation programme created to generate binary transmission time series for 100 MTDs where 5-MTDs exhibits periodic transmissions, other 5-MTDs exhibits random transmissions and rest of MTDs exhibits event-driven transmissions. Every event-driven transmitting MTD have a causal relationship with periodic transmitting MTD or random transmitting MTD. The periodic transmitting MTDs and random transmitting MTDs act as event triggering MTD. Therefore, we assume whenever IoT event occurred this event triggering MTD get affect by the event before other MTDs exhibits event-driven transmission. This assumption hold because of the geographically propagating nature of IoT events.\n",
    "\n",
    "## Import Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressbar(it, prefix=\"\", size=60, file=sys.stdout):\n",
    "    count = len(it)\n",
    "    def show(j):\n",
    "        x = int(size*j/count)\n",
    "        file.write(\"%s[%s%s] %i/%i\\r\" % (prefix, \"#\"*x, \".\"*(size-x), j, count))\n",
    "        file.flush()        \n",
    "    show(0)\n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i+1)\n",
    "    file.write(\"\\n\")\n",
    "    file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Transmission\n",
    "Random transmission can be happen at any given time step complete randomly. In other work for any given time step probability of transmission is 0.5 and probability of being silent is 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[############################################################] 5/5\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i in progressbar(range(0,5)):\n",
    "    Hb = choices((0,1), (0.5,0.5),k=60000)\n",
    "    dataset.append(Hb)\n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 60000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic Transmission\n",
    "Periodic transmission happens based on fixed repeating probability distribution where transmission probability is periodically set to a value within interval [0, 1] throughout the transmission time series. As an example transmission probability of time step (10N +X) is set to fix P probability where N is natural number and X = [0, 9] and P = [0, 1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[############################################################] 5/5\n"
     ]
    }
   ],
   "source": [
    "for i in progressbar(range(0,5)):\n",
    "    DS = []\n",
    "    for k in range(0,10):\n",
    "        TXp = np.random.randint(0,11)/10\n",
    "        Hb = choices((0,1), (TXp,1-TXp),k=6000)\n",
    "        DS.append(Hb)\n",
    "    DS = np.array(DS)\n",
    "    DS = np.transpose(DS)\n",
    "    DS = DS.reshape(1,-1)\n",
    "    dataset = np.vstack([dataset, DS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Driven Transmission\n",
    "Event-driven transmission occur with P correlated probability to periodic and random transmitting MTD after X time step to event is triggered where P = [0.8, 1] and T = [0, 9]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[############################################################] 10/10\n"
     ]
    }
   ],
   "source": [
    "for i in progressbar(range(0,10)):\n",
    "    Ep = rd.sample(range(1, 10), 9)\n",
    "    for k in range(0, 9):\n",
    "        X = [[0]]*Ep[k]\n",
    "        Ia = np.random.randint(8,11)/10\n",
    "        population = [1,0]\n",
    "        weights = [Ia,1-Ia]\n",
    "        for j in range(Ep[k], 60000):\n",
    "            if dataset[i][j-Ep[k]] == 1:\n",
    "                MTD = choices(population, weights)\n",
    "            if dataset[i][j-Ep[k]] == 0:\n",
    "                MTD = [0]\n",
    "            X.append(MTD)\n",
    "        X = np.array(X)\n",
    "        X = X.reshape(1,-1)\n",
    "        dataset = np.vstack([dataset, X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 60000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "## Shuffle dataset np array by row only, keep column order unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 60000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = dataset[:,:20000]\n",
    "validation = dataset[:,20000:40000]\n",
    "test = dataset[:,40000:60000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.DataFrame(training)\n",
    "validation = pd.DataFrame(validation)\n",
    "test = pd.DataFrame(test)\n",
    "\n",
    "training.to_csv('training.csv', index=False)\n",
    "validation.to_csv('validation.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('training.csv')\n",
    "validation  = pd.read_csv('validation.csv')\n",
    "test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[############################################################] 100/100\n"
     ]
    }
   ],
   "source": [
    "X_TRAIN = [[[]*1]*10]*19990\n",
    "X_TRAIN = np.array(X_TRAIN)\n",
    "Y_TRAIN = [[]*1]*19990\n",
    "Y_TRAIN = np.array(Y_TRAIN)\n",
    "for j in progressbar(range(0,100)):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    t = np.array(train.iloc[j, :]).reshape(-1,1)\n",
    "    for i in range(10, 20000):\n",
    "        X_train.append(t[i-10:i, 0])\n",
    "        Y_train.append(t[i, 0])\n",
    "    X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    Y_train = np.reshape(Y_train, (Y_train.shape[0],1))\n",
    "    X_TRAIN = np.concatenate((X_TRAIN, X_train),axis=2)\n",
    "    Y_TRAIN = np.concatenate((Y_TRAIN, Y_train),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independed training-feature of the matrix = X_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19990, 10, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depended training-feature of the matrix = Y_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19990, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_TRAIN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[############################################################] 100/100\n"
     ]
    }
   ],
   "source": [
    "X_VAL = [[[]*1]*10]*19990\n",
    "X_VAL = np.array(X_VAL)\n",
    "Y_VAL = [[]*1]*19990\n",
    "Y_VAL = np.array(Y_VAL)\n",
    "for j in progressbar(range(0,100)):\n",
    "    X_validation = []\n",
    "    Y_validation = []\n",
    "    t = np.array(train.iloc[j, :]).reshape(-1,1)\n",
    "    for i in range(10, 20000):\n",
    "        X_validation.append(t[i-10:i, 0])\n",
    "        Y_validation.append(t[i, 0])\n",
    "    X_validation, Y_validation = np.array(X_validation), np.array(Y_validation)\n",
    "    X_validation = np.reshape(X_validation, (X_validation.shape[0], X_validation.shape[1], 1))\n",
    "    Y_validation = np.reshape(Y_validation, (Y_validation.shape[0],1))\n",
    "    X_VAL = np.concatenate((X_VAL, X_validation),axis=2)\n",
    "    Y_VAL = np.concatenate((Y_VAL, Y_validation),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independed validation-feature of the matrix = X_VAL\n",
    "\n",
    "Depended validation-feature of the matrix = Y_VAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[############################################################] 100/100\n"
     ]
    }
   ],
   "source": [
    "X_TEST = [[[]*1]*10]*19990\n",
    "X_TEST = np.array(X_TEST)\n",
    "Y_TEST = [[]*1]*19990\n",
    "Y_TEST = np.array(Y_TEST)\n",
    "for j in progressbar(range(0,100)):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    t = np.array(test.iloc[j, :]).reshape(-1,1)\n",
    "    for i in range(10, 20000):\n",
    "        X_test.append(t[i-10:i, 0])\n",
    "        Y_test.append(t[i, 0])\n",
    "    X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    Y_test = np.reshape(Y_test, (Y_test.shape[0],1))\n",
    "    X_TEST = np.concatenate((X_TEST, X_test),axis=2)\n",
    "    Y_TEST = np.concatenate((Y_TEST, Y_test),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Pre-processed data (prepare for S3 bucket uploading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('train_restruct', dat_tr=X_TRAIN, lbl_tr=Y_TRAIN)\n",
    "np.savez('valid_restruct', dat_ts=X_VAL, lbl_ts=Y_VAL)\n",
    "np.savez('test_restruct', dat_ts=X_TEST, lbl_ts=Y_TEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
